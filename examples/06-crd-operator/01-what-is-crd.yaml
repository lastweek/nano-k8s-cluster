# Custom Resource Definition (CRD) - Basic Example
#
# A CRD extends Kubernetes API with your own custom resources.
# Think of it as adding a new "kind" of resource to Kubernetes.
#
# Why CRDs?
# - Extend Kubernetes for your specific needs
# - Create domain-specific APIs (e.g., ModelDeployment, TrainingJob)
# - Use kubectl to manage your custom resources
# - Build operators that automate your workflows
#
# Real-world examples:
# - Cert-Manager: Certificate, ClusterIssuer resources
# - NVIDIA Dynamo: DynamoGraphDeployment, DynamoGraphDeploymentRequest
# - Prometheus: Prometheus, Alertmanager resources
# - Crossplane: Composite resources for cloud infrastructure
#
# For LLM serving:
# - ModelDeployment: Deploy models with specialized config
# - TrainingJob: Distributed training jobs
# - ScalingPolicy: Custom autoscaling policies
#
# Usage:
#   kubectl apply -f 01-what-is-crd.yaml
#   kubectl get crds
#   kubectl delete -f 01-what-is-crd.yaml

---
# Custom Resource Definition
apiVersion: apiextensions.k8s.io/v1
kind: CustomResourceDefinition
metadata:
  name: llmmodels.ai.example.com  # Full name: <plural>.<group>
spec:
  group: ai.example.com           # API group (like "apps", "batch")
  names:
    plural: llmmodels             # Plural name: kubectl get llmmodels
    singular: llmmodel            # Singular name: kubectl get llmmodel
    kind: LLMModel                # Resource kind: kind: LLMModel
    shortNames:
    - llm                         # Short name: kubectl get llm
  scope: Namespaced               # Can be Namespaced or Cluster
  versions:
  - name: v1                      # API version
    served: true                  # Enable this version
    storage: true                 # Mark as storage version
    schema:
      openAPIV3Schema:
        type: object
        properties:
          spec:
            type: object
            properties:
              # Model configuration
              modelName:
                type: string
                description: "Name of the LLM model (e.g., llama-3-70b)"
              modelPath:
                type: string
                description: "Path to model weights"
              # Serving configuration
              replicas:
                type: integer
                minimum: 1
                default: 1
                description: "Number of model serving replicas"
              # GPU configuration
              gpuType:
                type: string
                enum: ["A100", "H100", "L40S", "T4"]
                default: "A100"
                description: "GPU type for serving"
              gpuMemory:
                type: string
                default: "80Gi"
                description: "GPU memory per replica"
              # Serving parameters
              maxTokens:
                type: integer
                default: 4096
                description: "Maximum tokens per request"
              temperature:
                type: number
                default: 0.7
                description: "Default sampling temperature"
              # Feature flags
              enableStreaming:
                type: boolean
                default: true
              enableCache:
                type: boolean
                default: true
            required:
            - modelName
            - modelPath
          status:
            type: object
            properties:
              phase:
                type: string
                description: "Current phase (Pending, Running, Failed)"
              replicas:
                type: integer
                description: "Actual number of replicas"
              readyReplicas:
                type: integer
                description: "Number of ready replicas"
              message:
                type: string
                description: "Human-readable message"

# After creating this CRD, you can use kubectl:
# kubectl get llmmodels
# kubectl describe llmmodel my-model
# kubectl delete llmmodel my-model

# The CRD alone just defines the API schema.
# To DO something with these resources, you need an OPERATOR (controller).
# See 02-simple-operator.yaml for the operator part.

# What we just created:
# ┌────────────────────────────────────────────────────────────┐
# │  CRD: LLMModel                                              │
# │  - Defines a new API resource                              │
# │  - Can be managed with kubectl                             │
# │  - Follows Kubernetes patterns                             │
# │  - Stored in etcd like other resources                     │
# └────────────────────────────────────────────────────────────┘
#                            │
#                            ▼
# ┌────────────────────────────────────────────────────────────┐
# │  Example Instance:                                          │
# │  apiVersion: ai.example.com/v1                             │
# │  kind: LLMModel                                             │
# │  metadata:                                                  │
# │    name: my-llama-model                                    │
# │  spec:                                                      │
# │    modelName: llama-3-70b                                  │
# │    replicas: 3                                             │
# │    gpuType: H100                                            │
# └────────────────────────────────────────────────────────────┘

# How this compares to NVIDIA Dynamo:
#
# Our CRD:                    NVIDIA Dynamo CRD:
# ┌─────────────┐            ┌──────────────────────────┐
# │ LLMModel    │            │ DynamoGraphDeployment     │
# ├─────────────┤            ├──────────────────────────┤
# │ modelName   │            │ model_name                │
# │ replicas    │            │ replicas                  │
# │ gpuType     │            │ tensor_parallel_size     │
# │ temperature │            │ pipeline_type             │
# └─────────────┘            │ placement_policy          │
#                            │ sla (latency, throughput) │
#                            └──────────────────────────┘
#
# Same concept, different domain-specific fields!
